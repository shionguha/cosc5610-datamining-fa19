{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homophile and social selection is what makes social networks uniques\n",
    "l--> similarities l---> proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Lang_Geraghty_Kozlova.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.YEA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only13 = df[df.YEA == 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only13['DAT'] = pd.to_datetime(only13.DAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get active voters only\n",
    "vc = only13.SRC.value_counts()\n",
    "vc = vc[vc>10]\n",
    "filter1 = only13.SRC.isin(vc.index)\n",
    "tt = only13[filter1].reset_index(drop = True)\n",
    "#tt = only13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_dataframe(tt, 'SRC', 'TGT', ['RES', 'VOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqTGT = tt.TGT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "color_map = []\n",
    "node_sizes = []\n",
    "labels = {}\n",
    "for node in G:\n",
    "    a = 0\n",
    "    if node in uniqTGT:\n",
    "        labels[node] = node\n",
    "        node_sizes.append(400)\n",
    "        a = tt[tt['TGT'] == str(node)].RES.values[0]\n",
    "        if a == 1:\n",
    "            color_map.append('green')\n",
    "        elif a == -1:\n",
    "            color_map.append('red')\n",
    "    else:\n",
    "        node_sizes.append(150)\n",
    "        if nx.betweenness_centrality(G)[str(node)]>.002:\n",
    "            labels[node] = node\n",
    "            color_map.append('magenta')\n",
    "        else:\n",
    "            color_map.append('black')\n",
    "        \n",
    "Gedge_colors = []\n",
    "for e in G.edges(data = True):\n",
    "    vote = e[2]['VOT']\n",
    "    if vote == 1:\n",
    "        Gedge_colors.append('cyan')\n",
    "    elif vote == -1:\n",
    "        Gedge_colors.append('orange')\n",
    "    else:\n",
    "        Gedge_colors.append('pink')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G:\n",
    "    if node not in uniqTGT:\n",
    "        if nx.betweenness_centrality(G)[str(node)]>.002:\n",
    "            print(node)\n",
    "            print(nx.betweenness_centrality(G)[str(node)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G)\n",
    "cent = nx.betweenness_centrality(G)\n",
    "node_CENTsize = [v*85000 for v in cent.values()]\n",
    "plt.figure(1,figsize=(33,16)) \n",
    "nx.draw(G, pos = pos, edge_color=Gedge_colors,node_color = color_map, \n",
    "        with_labels = False, node_size = node_CENTsize)\n",
    "nx.draw_networkx_labels(G,pos,labels,font_size=17,font_color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate probability of node getting voted on \n",
    "#New node entering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(G.degree, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(nx.degree_centrality(G).items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(nx.eigenvector_centrality(G).items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.closeness_centrality(G).items(), key=lambda kv: kv[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(nx.betweenness_centrality(G).items(), key=lambda kv: kv[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-clustering-connectivity-and-other-graph-properties-using-networkx/\n",
    "nx.center(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Lang_Geraghty_Kozlova2.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFrame.fillna(\" \", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe posVotes that contains all observations where VOT = 1\n",
    "posVotes = dataFrame[dataFrame['VOT'] == 1]\n",
    "posVotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe neutVotes that contains all observations where VOT = 0\n",
    "neutVotes = dataFrame[dataFrame['VOT'] == 0]\n",
    "neutVotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create dataframe negVotes that contains all observations where VOT = -1\n",
    "negVotes = dataFrame[dataFrame['VOT'] == -1]\n",
    "negVotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the size of the negVotes dataframe\n",
    "len(posVotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neutVotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(negVotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import the CountVectorizer and use it to fit the CLEAN_TXT of the negVotes\n",
    "#For the all the lines about finding the word frequency of positive, negative, and neutral votes,\n",
    "#the code was based on https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer().fit(negVotes['CLEAN_TXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a bag_of_words that will be used to find the frequency of words\n",
    "bag_of_words = vec.transform(negVotes['CLEAN_TXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sum the words\n",
    "sum_words = bag_of_words.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the frequency of each word\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorts the frequency of words from highest to lowest\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the words along with their frequency in the negative Comments\n",
    "print(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using a countVectorizer to fit all the positive comments\n",
    "posvec = CountVectorizer().fit(posVotes['CLEAN_TXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a bag_of_words that will be used to find the frequency of words\n",
    "pos_bag_of_words = posvec.transform(posVotes['CLEAN_TXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sum the words\n",
    "pos_sum_words = pos_bag_of_words.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the frequency of every word in the positive comments\n",
    "pos_words_freq = [(word, pos_sum_words[0, idx]) for word, idx in posvec.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort the frequency of the words in the positive comments\n",
    "pos_words_freq =sorted(pos_words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the words of the positive comments along with their frequencies\n",
    "print(pos_words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use CountVectorizer  to fit neutral comments\n",
    "neutvec = CountVectorizer().fit(neutVotes['CLEAN_TXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create bag of words for all the neutral comments\n",
    "neut_bag_of_words = neutvec.transform(neutVotes['CLEAN_TXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sum the words\n",
    "neut_sum_words = neut_bag_of_words.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the frequency of each word in the bag of words\n",
    "neut_words_freq = [(word, neut_sum_words[0, idx]) for word, idx in neutvec.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort the frequencies of each word highest first\n",
    "neut_words_freq =sorted(neut_words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Begin topic modeling for the negative comments \n",
    "neg_count_vect = CountVectorizer()\n",
    "neg_doc_term_matrix = neg_count_vect.fit_transform(negVotes['CLEAN_TXT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the LDA to pick out 10 topics in the negative comments\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDANeg = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "LDANeg.fit(neg_doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tells the probability distribution of words in a topic\n",
    "neg_first_topic = LDANeg.components_[2]\n",
    "print(neg_first_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of words in the corpus\n",
    "neg_doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve the top 20 words in a topic\n",
    "neg_top_topic_words = neg_first_topic.argsort()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the top 20 words\n",
    "print(neg_top_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the word distribution for a topic\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in neg_top_topic_words:\n",
    "    y.append(LDANeg.components_[2][i])\n",
    "    x.append(str(neg_count_vect.get_feature_names()[i]))\n",
    "\n",
    "plt.barh(x, y, color='blue')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Number of Times Word Appears in Topic 4\")\n",
    "plt.title(\"Word Distribution in Topic 4\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the 20 words in a topic\n",
    "for i in neg_top_topic_words:\n",
    "    print(neg_count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print the 20 words in each of the 10 topics\n",
    "for i,topic in enumerate(LDANeg.components_):\n",
    "    print('Top 10 words for topic %s:'%i)\n",
    "    L = [neg_count_vect.get_feature_names()[i] for i in topic.argsort()[-20:]]\n",
    "    print(\", \".join(L))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the topic values\n",
    "neg_topic_values = LDANeg.transform(neg_doc_term_matrix)\n",
    "neg_topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign each comment a topic value \n",
    "negVotes['NegLDATopic'] = neg_topic_values.argmax(axis=1)\n",
    "negVotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of how comments fall in each topic\n",
    "negVotes['NegLDATopic'].value_counts()[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neutral CountVectorizer for neutral votes\n",
    "neut_count_vect = CountVectorizer()\n",
    "neut_doc_term_matrix = neut_count_vect.fit_transform(neutVotes['CLEAN_TXT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA model for the neutral comments extracting 10 topics\n",
    "LDANeut = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "LDANeut.fit(neut_doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tells the probability distribution of words in a topic\n",
    "neut_first_topic = LDANeut.components_[5]\n",
    "print(neut_first_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of words in the neutral comments\n",
    "neut_doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The top 20 words in the topic\n",
    "neut_top_topic_words = neut_first_topic.argsort()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print top 20 words in topic\n",
    "print(neut_top_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the word distribution of neutral comments in topic 6\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "for i in neut_top_topic_words:\n",
    "    y1.append(LDANeut.components_[5][i])\n",
    "    x1.append(str(neut_count_vect.get_feature_names()[i]))\n",
    "\n",
    "plt.barh(x1, y1, color='blue')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Number of Times Word Appears in Topic 5\")\n",
    "plt.title(\"Word Distribution in Topic 5\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the top 20 words in the bet topic\n",
    "for i in neut_top_topic_words:\n",
    "    print(neut_count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print out top 20 words in the top 10 topics\n",
    "for i,topic in enumerate(LDANeut.components_):\n",
    "    print('Top 10 words for topic %s:'%i)\n",
    "    L = [neut_count_vect.get_feature_names()[i] for i in topic.argsort()[-20:]]\n",
    "    print (\", \".join(L))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the neutral topic values\n",
    "neut_topic_values = LDANeut.transform(neut_doc_term_matrix)\n",
    "neut_topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign a topic to each of the neutral comments\n",
    "neutVotes['NeutLDATopic'] = neut_topic_values.argmax(axis=1)\n",
    "neutVotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the topic distribution of how neutral comments fall into each topic\n",
    "neutVotes['NeutLDATopic'].value_counts()[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count Vectorizer for positive comments\n",
    "pos_count_vect = CountVectorizer()\n",
    "pos_doc_term_matrix = pos_count_vect.fit_transform(posVotes['CLEAN_TXT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA model for the positive comments\n",
    "LDAPos = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "LDAPos.fit(pos_doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tells the probability distribution of words in a topic\n",
    "pos_first_topic = LDAPos.components_[8]\n",
    "print(pos_first_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The number of words in the neutral comments\n",
    "pos_doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The top 20 words in a topic\n",
    "pos_top_topic_words = pos_first_topic.argsort()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print top 20 words in a topic\n",
    "print(pos_top_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot the word distribution for the most popular  topic \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "for i in pos_top_topic_words:\n",
    "    y1.append(LDAPos.components_[8][i])\n",
    "    x1.append(str(pos_count_vect.get_feature_names()[i]))\n",
    "\n",
    "plt.barh(x1, y1, color='blue')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Number of Times Word Appears in Topic 8\")\n",
    "plt.title(\"Positive Word Distribution in Topic 8\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Print the ten words in a topic\n",
    "for i in pos_top_topic_words:\n",
    "    print(pos_count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print the top 20 words for the top 10 topics\n",
    "for i,topic in enumerate(LDAPos.components_):\n",
    "    print('Top 20 words for topic %s:'%i)\n",
    "    L = [pos_count_vect.get_feature_names()[i] for i in topic.argsort()[-20:]]\n",
    "    print (\", \".join(L))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the positive topic values\n",
    "pos_topic_values = LDAPos.transform(pos_doc_term_matrix)\n",
    "pos_topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assign the topic values to a comment\n",
    "posVotes['PosLDATopic'] = pos_topic_values.argmax(axis=1)\n",
    "posVotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot the distribution of comments in each topic\n",
    "posVotes['PosLDATopic'].value_counts()[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new dataframe with all votes/comments that were assigned Topic 8\n",
    "posComments = posVotes[posVotes['PosLDATopic'] == 8]\n",
    "posComments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read some comments\n",
    "posComments[7905:7990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve the original comments to use as exemplar sentences\n",
    "print(nltk.word_tokenize(data['TXT'][49794]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Look at the version of the comment cleaned\n",
    "print(nltk.word_tokenize(posComments['CLEAN_TXT'][60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get a dataframe with all the negative Comments in the most freuqent topi \n",
    "negComments = negVotes[negVotes['NegLDATopic'] == 4]\n",
    "negComments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read some comments\n",
    "negComments[1460:1490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve the original comments to use as exemplar sentences\n",
    "print(nltk.word_tokenize(data['TXT'][79995]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve the cleaned versionof the comments\n",
    "print(nltk.word_tokenize(negComments['CLEAN_TXT'][53319]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dataframe with the neutral comments that are in the most common topic\n",
    "neutComments = neutVotes[neutVotes['NeutLDATopic'] == 5]\n",
    "neutComments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read some comments\n",
    "neutComments[490:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#retrieve the original comments to use as exemplar sentences\n",
    "print(nltk.word_tokenize(data['TXT'][97136]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#access to the cleaned version of the topics\n",
    "print(nltk.word_tokenize(neutComments['CLEAN_TXT'][158748]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use a TfidVectorizer to prepare an NMF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "doc_term_matrix = tfidf_vect.fit_transform(negVotes['CLEAN_TXT'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create an NMF model with 10 topics\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=10, random_state=0)\n",
    "nmf.fit(doc_term_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see the distribution of words\n",
    "first_topic = nmf.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints top 20 words for a topic\n",
    "for i in top_topic_words:\n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prints top 20 words for the top 10 topics\n",
    "for i,topic in enumerate(nmf.components_):\n",
    "    print('Top 20 words for topic %s:'%i)\n",
    "    L = [tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-20:]]\n",
    "    print u\", \".join(L)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot the Word distribution of most frequent topic\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "for i in top_topic_words:\n",
    "    y1.append(nmf.components_[0][i])\n",
    "    x1.append(str(tfidf_vect.get_feature_names()[i]))\n",
    "\n",
    "plt.barh(x1, y1, color='blue')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Number of Times Word Appears in Topic 4\")\n",
    "plt.title(\"Word Distribution in Topic 4\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assign a topic value to each of the negative comments\n",
    "topic_values = nmf.transform(doc_term_matrix)\n",
    "negVotes['NMFTopic'] = topic_values.argmax(axis=1)\n",
    "negVotes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the distribution of which comments ended up in which topic\n",
    "negVotes['NMFTopic'].value_counts()[:10].plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
